{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:24.205610Z","iopub.execute_input":"2025-11-10T14:23:24.206017Z","iopub.status.idle":"2025-11-10T14:23:27.528801Z","shell.execute_reply.started":"2025-11-10T14:23:24.205998Z","shell.execute_reply":"2025-11-10T14:23:27.527911Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.7.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.13.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.1.3)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.10.5)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.nn import GCNConv, GINConv, GATConv, SAGEConv, TransformerConv\nimport torch_geometric.transforms as T\nfrom torch.nn import Linear, Sequential, ReLU, BatchNorm1d\nimport torch_geometric.transforms as T\n\n# load dataset\ndataset = Planetoid(root='data/Planetoid', name='CiteSeer', transform=T.NormalizeFeatures())\ndata = dataset[0]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.530255Z","iopub.execute_input":"2025-11-10T14:23:27.530508Z","iopub.status.idle":"2025-11-10T14:23:27.609296Z","shell.execute_reply.started":"2025-11-10T14:23:27.530482Z","shell.execute_reply":"2025-11-10T14:23:27.608488Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Graph Isomorphism Network\nclass GIN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n        super().__init__()\n        nn1 = Sequential(Linear(in_channels, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n        nn2 = Sequential(Linear(hidden_channels, hidden_channels), ReLU(), Linear(hidden_channels, out_channels))\n        \n        self.conv1 = GINConv(nn1)\n        self.bn1 = BatchNorm1d(hidden_channels)\n        self.conv2 = GINConv(nn2)\n        self.dropout = dropout\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = self.bn1(x)\n        x = F.relu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.610067Z","iopub.execute_input":"2025-11-10T14:23:27.610279Z","iopub.status.idle":"2025-11-10T14:23:27.615583Z","shell.execute_reply.started":"2025-11-10T14:23:27.610263Z","shell.execute_reply":"2025-11-10T14:23:27.615064Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Graph Attention Network\nclass GAT(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=8, dropout=0.6):\n        super().__init__()\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        # second layer uses 1 head for final classification\n        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n        self.dropout = dropout\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.617124Z","iopub.execute_input":"2025-11-10T14:23:27.617326Z","iopub.status.idle":"2025-11-10T14:23:27.634265Z","shell.execute_reply.started":"2025-11-10T14:23:27.617309Z","shell.execute_reply":"2025-11-10T14:23:27.633595Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Graph Sample and aggregate\nclass GraphSAGE(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n        super().__init__()\n        self.conv1 = SAGEConv(in_channels, hidden_channels)\n        self.conv2 = SAGEConv(hidden_channels, out_channels)\n        self.dropout = dropout\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.634936Z","iopub.execute_input":"2025-11-10T14:23:27.635150Z","iopub.status.idle":"2025-11-10T14:23:27.651519Z","shell.execute_reply.started":"2025-11-10T14:23:27.635134Z","shell.execute_reply":"2025-11-10T14:23:27.650899Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#  GraphTransformer\nclass GraphTransformer(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.5):\n        super().__init__()\n        self.conv1 = TransformerConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        self.conv2 = TransformerConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n        self.dropout = dropout\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.652133Z","iopub.execute_input":"2025-11-10T14:23:27.652325Z","iopub.status.idle":"2025-11-10T14:23:27.664855Z","shell.execute_reply.started":"2025-11-10T14:23:27.652310Z","shell.execute_reply":"2025-11-10T14:23:27.664212Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def train(model, data):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data)\n    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n\n@torch.no_grad()\ndef evaluate(model, data):\n    model.eval()\n    out = model(data)\n    accs = []\n    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n        pred = out[mask].argmax(dim=1)\n        acc = (pred == data.y[mask]).sum() / mask.sum()\n        accs.append(acc.item())\n    return accs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.665479Z","iopub.execute_input":"2025-11-10T14:23:27.665660Z","iopub.status.idle":"2025-11-10T14:23:27.681413Z","shell.execute_reply.started":"2025-11-10T14:23:27.665646Z","shell.execute_reply":"2025-11-10T14:23:27.680882Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GIN(dataset.num_node_features, 64, dataset.num_classes).to(device)\ndata = data.to(device)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nbest_val_acc = 0\nbest_test_acc = 0\nfor epoch in range(1, 201):\n    loss = train(model, data)\n    train_acc, val_acc, test_acc = evaluate(model, data)\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_test_acc = test_acc\n    if epoch % 20 == 0 or epoch == 1:\n        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Train: {train_acc:.3f} | \"\n              f\"Val: {val_acc:.3f} | Test: {test_acc:.3f}\")\n\nprint(f\"Best Validation Acc: {best_val_acc:.3f} | Test Acc: {best_test_acc:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:27.682154Z","iopub.execute_input":"2025-11-10T14:23:27.682418Z","iopub.status.idle":"2025-11-10T14:23:29.699314Z","shell.execute_reply.started":"2025-11-10T14:23:27.682397Z","shell.execute_reply":"2025-11-10T14:23:29.698530Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Loss: 1.8424 | Train: 0.200 | Val: 0.206 | Test: 0.229\nEpoch 020 | Loss: 0.0208 | Train: 0.975 | Val: 0.498 | Test: 0.506\nEpoch 040 | Loss: 0.0014 | Train: 1.000 | Val: 0.634 | Test: 0.621\nEpoch 060 | Loss: 0.0035 | Train: 1.000 | Val: 0.640 | Test: 0.632\nEpoch 080 | Loss: 0.0020 | Train: 1.000 | Val: 0.642 | Test: 0.641\nEpoch 100 | Loss: 0.0030 | Train: 0.992 | Val: 0.586 | Test: 0.554\nEpoch 120 | Loss: 0.0012 | Train: 1.000 | Val: 0.572 | Test: 0.580\nEpoch 140 | Loss: 0.0017 | Train: 1.000 | Val: 0.522 | Test: 0.562\nEpoch 160 | Loss: 0.0005 | Train: 1.000 | Val: 0.562 | Test: 0.569\nEpoch 180 | Loss: 0.0013 | Train: 1.000 | Val: 0.614 | Test: 0.590\nEpoch 200 | Loss: 0.0009 | Train: 1.000 | Val: 0.626 | Test: 0.618\nBest Validation Acc: 0.666 | Test Acc: 0.648\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GAT(dataset.num_node_features, 8, dataset.num_classes).to(device)\ndata = data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nbest_val_acc = 0\nbest_test_acc = 0\nfor epoch in range(1, 201):\n    loss = train(model, data)\n    train_acc, val_acc, test_acc = evaluate(model, data)\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_test_acc = test_acc\n    if epoch % 20 == 0 or epoch == 1:\n        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Train: {train_acc:.3f} | \"\n              f\"Val: {val_acc:.3f} | Test: {test_acc:.3f}\")\n\nprint(f\"Best Validation Acc: {best_val_acc:.3f} | Test Acc: {best_test_acc:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:29.700232Z","iopub.execute_input":"2025-11-10T14:23:29.700517Z","iopub.status.idle":"2025-11-10T14:23:31.489204Z","shell.execute_reply.started":"2025-11-10T14:23:29.700492Z","shell.execute_reply":"2025-11-10T14:23:31.488571Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Loss: 1.7916 | Train: 0.167 | Val: 0.232 | Test: 0.181\nEpoch 020 | Loss: 1.5540 | Train: 0.908 | Val: 0.734 | Test: 0.721\nEpoch 040 | Loss: 1.2004 | Train: 0.933 | Val: 0.726 | Test: 0.720\nEpoch 060 | Loss: 0.9414 | Train: 0.950 | Val: 0.716 | Test: 0.699\nEpoch 080 | Loss: 0.7527 | Train: 0.967 | Val: 0.692 | Test: 0.668\nEpoch 100 | Loss: 0.8624 | Train: 0.975 | Val: 0.720 | Test: 0.698\nEpoch 120 | Loss: 0.7109 | Train: 0.983 | Val: 0.716 | Test: 0.697\nEpoch 140 | Loss: 0.6868 | Train: 0.975 | Val: 0.690 | Test: 0.669\nEpoch 160 | Loss: 0.8070 | Train: 0.983 | Val: 0.714 | Test: 0.708\nEpoch 180 | Loss: 0.7319 | Train: 0.967 | Val: 0.722 | Test: 0.709\nEpoch 200 | Loss: 0.7089 | Train: 0.975 | Val: 0.704 | Test: 0.693\nBest Validation Acc: 0.748 | Test Acc: 0.728\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GraphSAGE(dataset.num_node_features, 64, dataset.num_classes).to(device)\ndata = data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nbest_val_acc = 0\nbest_test_acc = 0\nfor epoch in range(1, 201):\n    loss = train(model, data)\n    train_acc, val_acc, test_acc = evaluate(model, data)\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_test_acc = test_acc\n    if epoch % 20 == 0 or epoch == 1:\n        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Train: {train_acc:.3f} | \"\n              f\"Val: {val_acc:.3f} | Test: {test_acc:.3f}\")\n\nprint(f\"Best Validation Acc: {best_val_acc:.3f} | Test Acc: {best_test_acc:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:31.491134Z","iopub.execute_input":"2025-11-10T14:23:31.491413Z","iopub.status.idle":"2025-11-10T14:23:33.575211Z","shell.execute_reply.started":"2025-11-10T14:23:31.491395Z","shell.execute_reply":"2025-11-10T14:23:33.574431Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Loss: 1.7927 | Train: 0.233 | Val: 0.058 | Test: 0.077\nEpoch 020 | Loss: 0.6659 | Train: 1.000 | Val: 0.692 | Test: 0.685\nEpoch 040 | Loss: 0.1849 | Train: 1.000 | Val: 0.682 | Test: 0.685\nEpoch 060 | Loss: 0.1383 | Train: 1.000 | Val: 0.682 | Test: 0.688\nEpoch 080 | Loss: 0.1201 | Train: 1.000 | Val: 0.680 | Test: 0.695\nEpoch 100 | Loss: 0.1013 | Train: 1.000 | Val: 0.702 | Test: 0.697\nEpoch 120 | Loss: 0.0952 | Train: 1.000 | Val: 0.698 | Test: 0.703\nEpoch 140 | Loss: 0.0893 | Train: 1.000 | Val: 0.696 | Test: 0.706\nEpoch 160 | Loss: 0.0797 | Train: 1.000 | Val: 0.686 | Test: 0.700\nEpoch 180 | Loss: 0.0753 | Train: 1.000 | Val: 0.696 | Test: 0.688\nEpoch 200 | Loss: 0.0754 | Train: 1.000 | Val: 0.686 | Test: 0.698\nBest Validation Acc: 0.710 | Test Acc: 0.707\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GraphTransformer(\n        in_channels = dataset.num_node_features,\n        hidden_channels = 64,\n        out_channels = dataset.num_classes,\n        heads = 4,\n        dropout = 0.5\n    ).to(device)\ndata = data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nbest_val_acc = 0\nbest_test_acc = 0\nfor epoch in range(1, 201):\n    loss = train(model, data)\n    train_acc, val_acc, test_acc = evaluate(model, data)\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_test_acc = test_acc\n    if epoch % 20 == 0 or epoch == 1:\n        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Train: {train_acc:.3f} | \"\n              f\"Val: {val_acc:.3f} | Test: {test_acc:.3f}\")\n\nprint(f\"Best Validation Acc: {best_val_acc:.3f} | Test Acc: {best_test_acc:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:33.576079Z","iopub.execute_input":"2025-11-10T14:23:33.576507Z","iopub.status.idle":"2025-11-10T14:23:37.245552Z","shell.execute_reply.started":"2025-11-10T14:23:33.576486Z","shell.execute_reply":"2025-11-10T14:23:37.244872Z"}},"outputs":[{"name":"stdout","text":"Epoch 001 | Loss: 1.7906 | Train: 0.333 | Val: 0.172 | Test: 0.191\nEpoch 020 | Loss: 0.3443 | Train: 1.000 | Val: 0.698 | Test: 0.696\nEpoch 040 | Loss: 0.1784 | Train: 1.000 | Val: 0.682 | Test: 0.691\nEpoch 060 | Loss: 0.1031 | Train: 1.000 | Val: 0.688 | Test: 0.693\nEpoch 080 | Loss: 0.1158 | Train: 1.000 | Val: 0.682 | Test: 0.675\nEpoch 100 | Loss: 0.0993 | Train: 1.000 | Val: 0.692 | Test: 0.689\nEpoch 120 | Loss: 0.0830 | Train: 1.000 | Val: 0.636 | Test: 0.651\nEpoch 140 | Loss: 0.0979 | Train: 1.000 | Val: 0.700 | Test: 0.696\nEpoch 160 | Loss: 0.0764 | Train: 1.000 | Val: 0.682 | Test: 0.701\nEpoch 180 | Loss: 0.0666 | Train: 1.000 | Val: 0.676 | Test: 0.701\nEpoch 200 | Loss: 0.0920 | Train: 1.000 | Val: 0.666 | Test: 0.680\nBest Validation Acc: 0.724 | Test Acc: 0.694\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Investigate the grapth without edges\nclass DeepMLP(torch.nn.Module):\n    def __init__(self, in_feats, hidden_feats, num_classes, dropout=0.6):\n        super().__init__()\n        self.fc1 = torch.nn.Linear(in_feats, hidden_feats)\n        self.fc2 = torch.nn.Linear(hidden_feats, hidden_feats)\n        self.fc3 = torch.nn.Linear(hidden_feats, hidden_feats)\n        self.fc4 = torch.nn.Linear(hidden_feats, num_classes)\n        self.dropout = dropout\n\n    def forward(self, data):\n        x = data.x\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = F.relu(self.fc3(x))\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.fc4(x)\n        return F.log_softmax(x, dim=1)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = DeepMLP(dataset.num_features, hidden_feats=64, num_classes=dataset.num_classes, dropout=0.6).to(device)\ndata = data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nbest_val_acc = 0\nfor epoch in range(1, 301):\n    loss = train(model, data)\n    train_acc, val_acc, test_acc = evaluate(model, data)\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_test_acc = test_acc\n    if epoch % 10 == 0:\n        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val: {val_acc:.4f} | Test: {test_acc:.4f}\")\n\nprint(f\"\\nBest Test Accuracy (Deep MLP baseline): {best_test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T14:23:37.246200Z","iopub.execute_input":"2025-11-10T14:23:37.246475Z","iopub.status.idle":"2025-11-10T14:23:38.384044Z","shell.execute_reply.started":"2025-11-10T14:23:37.246447Z","shell.execute_reply":"2025-11-10T14:23:38.383422Z"}},"outputs":[{"name":"stdout","text":"Epoch 010 | Loss: 1.7915 | Val: 0.1720 | Test: 0.1820\nEpoch 020 | Loss: 1.7947 | Val: 0.2120 | Test: 0.2310\nEpoch 030 | Loss: 1.7572 | Val: 0.4500 | Test: 0.4020\nEpoch 040 | Loss: 1.5099 | Val: 0.4020 | Test: 0.3900\nEpoch 050 | Loss: 1.0766 | Val: 0.3500 | Test: 0.3650\nEpoch 060 | Loss: 0.8002 | Val: 0.3840 | Test: 0.4230\nEpoch 070 | Loss: 0.6698 | Val: 0.4000 | Test: 0.4120\nEpoch 080 | Loss: 0.4889 | Val: 0.4040 | Test: 0.4150\nEpoch 090 | Loss: 0.6099 | Val: 0.3940 | Test: 0.4180\nEpoch 100 | Loss: 0.5398 | Val: 0.3500 | Test: 0.4030\nEpoch 110 | Loss: 0.4407 | Val: 0.3400 | Test: 0.3910\nEpoch 120 | Loss: 0.3067 | Val: 0.3540 | Test: 0.4040\nEpoch 130 | Loss: 0.2570 | Val: 0.3920 | Test: 0.4080\nEpoch 140 | Loss: 0.2465 | Val: 0.3660 | Test: 0.4350\nEpoch 150 | Loss: 0.3952 | Val: 0.3780 | Test: 0.4330\nEpoch 160 | Loss: 0.2394 | Val: 0.3760 | Test: 0.4530\nEpoch 170 | Loss: 0.1446 | Val: 0.4040 | Test: 0.4560\nEpoch 180 | Loss: 0.3413 | Val: 0.3580 | Test: 0.4140\nEpoch 190 | Loss: 0.2564 | Val: 0.3660 | Test: 0.4480\nEpoch 200 | Loss: 0.1808 | Val: 0.3420 | Test: 0.4060\nEpoch 210 | Loss: 0.2490 | Val: 0.3820 | Test: 0.4610\nEpoch 220 | Loss: 0.1746 | Val: 0.3880 | Test: 0.4540\nEpoch 230 | Loss: 0.2667 | Val: 0.3840 | Test: 0.4440\nEpoch 240 | Loss: 0.2908 | Val: 0.4180 | Test: 0.4700\nEpoch 250 | Loss: 0.3007 | Val: 0.3920 | Test: 0.4570\nEpoch 260 | Loss: 0.3730 | Val: 0.4100 | Test: 0.4700\nEpoch 270 | Loss: 0.2454 | Val: 0.3600 | Test: 0.4320\nEpoch 280 | Loss: 0.2210 | Val: 0.4240 | Test: 0.4880\nEpoch 290 | Loss: 0.2862 | Val: 0.4140 | Test: 0.4590\nEpoch 300 | Loss: 0.1987 | Val: 0.4440 | Test: 0.4950\n\nBest Test Accuracy (Deep MLP baseline): 0.4020\n","output_type":"stream"}],"execution_count":31}]}